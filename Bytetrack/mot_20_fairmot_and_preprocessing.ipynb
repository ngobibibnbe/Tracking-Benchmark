{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "import numpy as np  \n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "#! pip install mpmath\n",
    "from mpmath import *\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import datetime as dt\n",
    "import json \n",
    "import copy\n",
    "import motmetrics as mm\n",
    "import re\n",
    "import pandas as pd \n",
    "from ATQ import adding_atq\n",
    "from forwardBackward import process_forwad_backward\n",
    "from utils import put_results_on_video\n",
    "\n",
    "import os \n",
    "import time \n",
    "\n",
    "import pandas as pd \n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "import numpy as np  \n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "#! pip install mpmath\n",
    "from mpmath import *\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import datetime as dt\n",
    "import json \n",
    "import copy\n",
    "import motmetrics as mm\n",
    "import re\n",
    "import pandas as pd \n",
    "from ATQ import adding_atq\n",
    "from forwardBackward import process_forwad_backward\n",
    "import os \n",
    "import time \n",
    "\n",
    "import os\n",
    "import json \n",
    "import cv2\n",
    "import pandas as pd\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "####get all dataset names \n",
    "def get_all_folders(path):\n",
    "    folders = [f.name for f in os.scandir(path) if f.is_dir() and 'MOT' in f.name]\n",
    "    return folders\n",
    "\n",
    "def convert_mot_format_to_json_format(gt_path=None,destination_path=None):\n",
    "    \"\"\"\n",
    "        read the MOT17 format and store in our dictionnary tracking format at the destination provided\n",
    "    \"\"\"\n",
    "    with open(gt_path, 'r') as file:\n",
    "        # Read each line in the file\n",
    "        tracking={}\n",
    "        \n",
    "        for line in file:\n",
    "            # Remove any trailing whitespace/newline characters and split by comma\n",
    "            #print(line.strip())\n",
    "            # ['frame', 'id', 'bbox_left', 'bbox_top', 'bbox_width', 'bbox_height', 'confidence', 'class', 'visibility']\n",
    "            frame_id, id, x,y,w,h,conf,class_,_ = line.strip().split(',')\n",
    "            \"\"\"print(line.strip().split(','))\n",
    "            print(frame_id,id,x,y,w,h)\"\"\"\n",
    "            # Print the extracted elements for each line\n",
    "            if int(class_)==1:\n",
    "                cr_frame_id = str(int(frame_id)-1) #because halfs start at one\n",
    "                if cr_frame_id not in tracking.keys():\n",
    "                    tracking[cr_frame_id]={}\n",
    "                tracking[cr_frame_id][id]=[int(x),int(y),int(w),int(h)]\n",
    "    tracking= {key: tracking[key] for key in sorted(tracking)}\n",
    "    os.makedirs(os.path.dirname(destination_path), exist_ok=True)\n",
    "    with open(destination_path, \"w\") as file:\n",
    "        json.dump(tracking,file)\n",
    "    print('tracking saved at', destination_path)\n",
    "    return tracking\n",
    "\n",
    "base_path =\"/data/home/sophie/sophie_2024-10-08/uncertain-identity-aware-tracking/Bytetrack/YOLOX_outputs/yolox_x_mix_mot20_ch/track_results\"\n",
    "annotation_path=\"/data/home/sophie/sophie_2024-10-08/uncertain-identity-aware-tracking/Bytetrack/tools/datasets/MOT20/train\"\n",
    "path = \"/data/home/sophie/sophie_2024-10-08/uncertain-identity-aware-tracking/Bytetrack/tools/datasets/MOT20/train\"\n",
    "folders = get_all_folders(path)\n",
    "print(folders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bytetrack_re_id import produce_re_id_results \n",
    "\n",
    "def read_data(file):\n",
    "    #here we will go through detections of deepsort \n",
    "    import json\n",
    "    track={}\n",
    "    with open(file) as f:\n",
    "        json_file = json.load(f) \n",
    "\n",
    "    for frame, detections in json_file.items():\n",
    "        frame=int(frame)\n",
    "        track[frame]={}\n",
    "        for id, detection in detections.items():\n",
    "            track[frame][id]={}\n",
    "            track[frame][id][\"rectangle\"]= tuple(detection)\n",
    "\n",
    "    return track\n",
    "\n",
    "def read_data_for_video_generation(file):\n",
    "    #here we will go through detections of deepsort \n",
    "    import json\n",
    "    track={}\n",
    "    with open(file) as f:\n",
    "        json_file = json.load(f) \n",
    "\n",
    "    for frame, detections in json_file.items():\n",
    "        frame=str(frame)\n",
    "        track[frame]={}\n",
    "        for id, detection in detections.items():\n",
    "            track[frame][id]={}\n",
    "            track[frame][id]= tuple(detection)\n",
    "\n",
    "    return track\n",
    "\n",
    "def iou (boxA,boxB):\n",
    "    boxA=[boxA[0],boxA[1],boxA[0]+boxA[2],boxA[1]+boxA[3]]\n",
    "    boxB=[boxB[0],boxA[1],boxB[0]+boxB[2],boxB[1]+boxB[3]]\n",
    "    xA = max(boxA[0], boxB[0])\n",
    "    yA = max(boxA[1], boxB[1])\n",
    "    xB = min(boxA[2], boxB[2])\n",
    "    yB = min(boxA[3], boxB[3])\n",
    "    # compute the area of intersection rectangle\n",
    "    interArea = max(0, xB - xA + 1) * max(0, yB - yA + 1)\n",
    "    # compute the area of both the prediction and ground-truth\n",
    "    # rectangles\n",
    "    boxAArea = abs((boxA[2] - boxA[0] + 1) * (boxA[3] - boxA[1] + 1))\n",
    "    boxBArea = abs((boxB[2] - boxB[0] + 1) * (boxB[3] - boxB[1] + 1))\n",
    "    # compute the intersection over union by taking the intersection\n",
    "    # area and dividing it by the sum of prediction + ground-truth\n",
    "    # areas - the interesection area\n",
    "    iou = interArea / float(boxAArea + boxBArea - interArea)\n",
    "    return iou  #np.linalg.norm(np.array([float(track[0]), float(track[1])+float(track[3])/2])-np.array([600,17.5]))\n",
    "\n",
    "\n",
    "\n",
    "def evaluate (tracks,track_result, limit=float(\"inf\"),column_indice= \"model\") :\n",
    "    acc = mm.MOTAccumulator(auto_id=False)\n",
    "    for key in sorted(tracks.keys()):\n",
    "        track=tracks[key]\n",
    "        if key in  track_result.keys()  :\n",
    "            frame_detection=track_result[key]\n",
    "            real_animals=np.array([list(individual[\"rectangle\"]) for individual  in list(track.values())])\n",
    "            hypothesis_animal= np.array([list(individual[\"rectangle\"]) for individual  in list(frame_detection.values())])\n",
    "            #print(real_animals, \"*****\", hypothesis_animal)\n",
    "            distances = mm.distances.iou_matrix(real_animals, hypothesis_animal, max_iou=0.75)\n",
    "            #print(\"deepsort\",hypothesis_animal)\n",
    "            #print(\"real\",real_animals)\n",
    "            #print(distances)\n",
    "            #print(real_animals)\n",
    "            \"\"\"try:\n",
    "                print(\"****\",acc,)\n",
    "                acc.update([float(key1) for key1 in list(track.keys())],[ 100000+float(re.search(r'^\\d+', key1)[0]) for key1 in frame_detection.keys()],distances, frameid=int(key))\n",
    "            except Exception as e :\n",
    "                print(\"***\",e)\n",
    "                for key1 in list(frame_detection.keys()):\n",
    "                    print(key1)# re.search(r'^\\d+', key1))\n",
    "                return 0\"\"\"\n",
    "            acc.update([float(key1) for key1 in list(track.keys())],[ float(re.search(r'^\\d+', key1)[0]) for key1 in frame_detection.keys()],distances, frameid=int(key))\n",
    "        if int(key)>= limit:\n",
    "              break\n",
    "    \n",
    "\n",
    "    mh = mm.metrics.create()\n",
    "    summary = mh.compute_many(\n",
    "        [acc],\n",
    "        #[acc_deepsort, acc_deeplabcut],\n",
    "        #metrics=mm.metrics.motchallenge_metrics,\n",
    "        #metrics=['idf1','num_frames', 'mota', 'motp'],\n",
    "        names=[\"model_name\"], #['deepsort','deeplabcut'],\n",
    "        generate_overall=True\n",
    "        )\n",
    "\n",
    "    strsummary = mm.io.render_summary(\n",
    "        summary,\n",
    "        formatters=mh.formatters,\n",
    "        namemap=mm.io.motchallenge_metric_names\n",
    "    )\n",
    "    #print(\"cumulative summary o\")\n",
    "    #print(strsummary)\n",
    "    #print(summary.columns)\n",
    "\n",
    "    idf1=summary[\"idf1\"].loc[\"model_name\"]\n",
    "    \"\"\"for col in summary.columns:\n",
    "        summary.columns = summary.columns.str.replace(col, col+'_'+column_indice)\"\"\"\n",
    "\n",
    "    return idf1\n",
    "\n",
    "\n",
    "def precise_accuracy_track(label_track, model_track, basic_tracker=False,gt_base_number =-2):#4800):\n",
    "    \"\"\"cette fonction calcule le f1-score recall, accuracy des model par rapport au background\n",
    "    dedans, les score des trackers et des hMM based tracker sont calculés différemment car quand le hmm based tracker est seuillé, \n",
    "    il y'a des id de track qu'il ne retourne pas dans son fichier de resultat.\n",
    "\n",
    "    Args:\n",
    "        label_track (_type_): _description_\n",
    "        model_track (_type_): _description_\n",
    "        basic_tracker (bool, optional): _description_. Defaults to False.\n",
    "\n",
    "    Returns:\n",
    "        _type_: _description_\n",
    "    \"\"\"\n",
    "    \n",
    "    idf1 = evaluate(label_track,model_track)\n",
    "    \n",
    "    start=True \n",
    "    nbr_frame=0\n",
    "    nbr_frame_acc=0\n",
    "    acc =0\n",
    "    rec=0\n",
    "    \"\"\"if basic_tracker==True:\n",
    "        matching={}\n",
    "        for frame_id in label_track.keys():\n",
    "            for label_atq, label_box in label_track[frame_id].items() : \n",
    "                if label_atq not in matching.keys() and label_atq!=\"observed\":\n",
    "                    matching[label_atq]=None \n",
    "                    break\"\"\"\n",
    "            \n",
    "    \n",
    "    def match_track_and_atq(label_track, model_track):\n",
    "            \n",
    "            matching={}\n",
    "            label_track_only_concerned = {}\n",
    "            for frame_id in label_track.keys():\n",
    "                label_track_only_concerned[frame_id]= {}\n",
    "                if frame_id in model_track.keys() :\n",
    "                    for label_atq, label_box in label_track[frame_id].items() : \n",
    "                        if float(label_atq)>gt_base_number:\n",
    "                            label_track_only_concerned[frame_id][label_atq] = label_track[frame_id][label_atq]\n",
    "                            \n",
    "                        if label_atq not in matching.keys():\n",
    "                            max_iou=float('-inf')\n",
    "                            for model_atq, model_box in model_track[frame_id].items(): \n",
    "                                #print(model_atq)\n",
    "                                if  label_atq!=\"observed\" and model_atq!=\"observed\":#fix the problem with the obseved on the label \n",
    "                                    \n",
    "                                    \"\"\"if str(model_atq)==str(label_atq):\n",
    "                                        print(model_atq, model_box[\"rectangle\"], label_box[\"rectangle\"])\n",
    "                                    \"\"\"\n",
    "                                    \n",
    "                                    tmp = iou(model_box[\"rectangle\"], label_box[\"rectangle\"])\n",
    "                                    if tmp>=max_iou:\n",
    "                                        matching [label_atq]=model_atq\n",
    "                                        max_iou =tmp\n",
    "                \n",
    "                if len(matching.keys())== len(label_track[frame_id].keys()):\n",
    "                    break\n",
    "            return label_track_only_concerned , {value:key for key, value in matching.items() if float(key)>gt_base_number}\n",
    "    \n",
    "    \n",
    "    if basic_tracker==True:\n",
    "        label_tracki, matching = match_track_and_atq(label_track, model_track)\n",
    "    else:\n",
    "        min_frame =min([int(i) for i in list(label_track.keys())])\n",
    "        matching= {k:k for k in label_track[min_frame].keys() if  'identities' not in k and float(k)>gt_base_number}\n",
    "    for frame_id in label_track.keys() :\n",
    "        if frame_id in model_track.keys() :\n",
    "            nbr_frame+=1\n",
    "            matching_frame={}\n",
    "            taken_atq=[]\n",
    "            remaining_atq=[label_atq for label_atq in label_track[frame_id].keys()]\n",
    "            for model_atq, model_box in model_track[frame_id].items() :\n",
    "                    max_iou=0\n",
    "                    atq_matching_model =None\n",
    "                    for  label_atq, label_box in label_track[frame_id].items():\n",
    "                        if  label_atq!=\"observed\" and model_atq!=\"observed\" :#fix the problem with the obseved on the label \n",
    "                            tmp = iou(model_box[\"rectangle\"], label_box[\"rectangle\"])\n",
    "                            if tmp>max_iou and label_atq not in taken_atq:\n",
    "                                max_iou =tmp\n",
    "                                atq_matching_model = label_atq\n",
    "                    if atq_matching_model is not None:\n",
    "                        taken_atq.append(atq_matching_model)\n",
    "                                \n",
    "                    #if basic_tracker==True:\n",
    "                    if model_atq in matching.keys(): #ca c'est pour les modèles qui crèent trop de nouvelles identités\n",
    "                            matching_frame[matching[model_atq] ]=atq_matching_model \n",
    "                    else:\n",
    "                        if basic_tracker:\n",
    "                            if atq_matching_model not in matching.values():\n",
    "                                #print(atq_matching_model,\"new atq at frameid:\", frame_id,\"for track_id\",model_atq, matching)\n",
    "                                #the atq could be assign to a new model identity\n",
    "                                matching[model_atq ]=atq_matching_model \n",
    "                                matching_frame[matching[model_atq] ]=atq_matching_model \n",
    "                            else:\n",
    "                                #remettreprint(atq_matching_model, 'atq could not be assigne to the model id :',model_atq)\n",
    "                                matching_frame[model_atq ]=None\n",
    "                        else:\n",
    "                            #matching[atq_matching_model ]=atq_matching_model\n",
    "                            matching[model_atq ]=model_atq \n",
    "                            matching_frame[matching[model_atq] ]=atq_matching_model\n",
    "            remaining_atq =list( set( remaining_atq) -  set(taken_atq))\n",
    "            \n",
    "                                    \n",
    "            filtered ={key:value for key,value in matching_frame.items() if value==key }\n",
    "            \n",
    "            if len(matching_frame.keys())!=0:\n",
    "                nbr_frame_acc+=1\n",
    "                #print(frame_id, \"(\",len(label_track[frame_id]),\")\",len(matching_frame), (len([label_atq  for label_atq in matching_frame.values() if label_atq is not None]) + len(remaining_atq)), matching_frame)\n",
    "                acc = acc + len(filtered.keys())/ len(matching_frame.keys())\n",
    "                rec = rec+ len(filtered.keys())/ (len([label_atq  for label_atq in matching_frame.values() if label_atq is not None]) + len(remaining_atq))\n",
    "                if len(filtered.keys())/ len(label_track[frame_id].keys())>1:\n",
    "                    print(len(filtered.keys()), len(label_track[frame_id].keys()))\n",
    "                    print(\"stop\")\n",
    "        else:\n",
    "            print(\"weird thing\", frame_id, \"not in model_track\")#, model_track.keys())\n",
    "\n",
    "    \n",
    "    acc = acc/nbr_frame_acc\n",
    "    rec=rec/nbr_frame\n",
    "    print(acc, rec) \n",
    "\n",
    "    f1=2*acc*rec/(acc+rec)\n",
    "    return acc  , rec , f1  , idf1 \n",
    "               \n",
    "                           \n",
    "\n",
    "\n",
    "def put_val_half_tracking(file_path, dataset_name=\"\"): \n",
    "    base_path =\"/data/home/sophie/sophie_2024-10-08/uncertain-identity-aware-tracking/Bytetrack/tools/datasets/MOT20/train/\"\n",
    "    dataset_path = os.path.join(base_path,dataset_name)\n",
    "    \n",
    "    gt_half_path=os.path.join(dataset_path,\"gt/gt_val_half.txt\")\n",
    "\n",
    "    tracking_half =convert_mot_format_to_json_format(gt_half_path,'trash/trash.json')\n",
    "    tracking_complete =convert_mot_format_to_json_format(os.path.join(dataset_path,\"gt/gt.txt\"),'trash/trash.json')\n",
    "\n",
    "    start_half = len(tracking_complete.keys()) -  len(tracking_half.keys()) -1\n",
    "    #######################################\n",
    "    ######Store the empty half gt video####\n",
    "    #######################################\n",
    "    #length_half =len (tracking.keys()) #length of the half\n",
    "    new_track={}\n",
    "    with open(file_path, \"r\") as file:\n",
    "        track = json.load(file)\n",
    "\n",
    "\n",
    "    for new_key in range (len(tracking_half.keys()) ):\n",
    "        new_track[str(new_key)] = track[str(new_key+start_half)]\n",
    "    \n",
    "    \n",
    "    file_path=file_path.split(dataset_name)[0] + '/'+dataset_name+ '/'+dataset_name+\".json\"\n",
    "        \n",
    "    with open(file_path.split(\".json\")[0]+\"_DBN_result_half_val.json\", \"w\") as file:\n",
    "        json.dump(new_track, file)\n",
    "    \n",
    "    \n",
    "    '''file_path = '/home/sophie/uncertain-identity-aware-tracking/Bytetrack/YOLOX_outputs/fairmot_json_files_hmm_format/'+dataset_name.split(\"FRCNN\")[0]+\"SDP.json\"\n",
    "    new_track={}\n",
    "    with open(file_path, \"r\") as file:\n",
    "        track = json.load(file)\n",
    "        \n",
    "    for new_key in range (len(tracking_half.keys()) ):\n",
    "        new_track[str(new_key)] = track[str(new_key+start_half)]\n",
    "        #print(len(new_track[str(new_key)] [\"previous\"]), len(new_track[str(new_key)] [\"current\"]), np.array(new_track[str(new_key)] [\"matrice\"]).shape)\n",
    "    with open(file_path.split(\".json\")[0]+\"_half_val.json\", \"w\") as file:\n",
    "        json.dump(new_track, file)'''\n",
    "    \n",
    "    \n",
    "        \n",
    "def generate_tracking_result_from_observation(dbn_file, tracking_result_file):\n",
    "    with open(dbn_file,\"r\") as file:\n",
    "        data=json.load(file)\n",
    "    result_track={}\n",
    "\n",
    "    for frame_id,content in  data.items():\n",
    "        result_track[str(frame_id)]={}\n",
    "        for track in content[\"current\"]:\n",
    "            track_id= track[\"track_id\"]\n",
    "            if track_id is not None:\n",
    "                result_track[str(frame_id)][track_id]=track[\"location\"]\n",
    "                \n",
    "    with open(tracking_result_file, \"w\") as file:\n",
    "        json.dump(result_track, file)\n",
    "    print(\"tracking saved at\", tracking_result_file)\n",
    "home_folder = \"/data/home/sophie/sophie_2024-10-08/uncertain-identity-aware-tracking/Bytetrack/\"\n",
    "\n",
    "for dataset_name in folders:\n",
    "    if dataset_name != \"MOT20-01\":\n",
    "        continue\n",
    "    base_path= home_folder+\"YOLOX_outputs/yolox_x_mix_mot20_ch/Fairmot/\"+dataset_name+\"/\"+dataset_name\n",
    "    os.makedirs(base_path, exist_ok=True)\n",
    "    gt_video=home_folder+\"YOLOX_outputs/yolox_x_mix_mot20_ch/track_results/videos/\"+dataset_name+\"/gt_video.mp4\"  \n",
    "    tracker_video = gt_video.split(\"gt_video\")[0]+\"fairmot_tracking.mp4\"\n",
    "    #dbn_file= \"/home/sophie/uncertain-identity-aware-tracking/Bytetrack/YOLOX_outputs/yolox_x_ablation/track_results/\"+dataset_name+\"/fairmot/\"+dataset_name.split(\"-\")[0]+\"-\"+dataset_name.split(\"-\")[1]+\"-SDP.json\"\n",
    "    dbn_file=home_folder+\"YOLOX_outputs/yolox_x_mix_mot20_ch/Fairmot/\"+dataset_name+\"/\"+dataset_name+\".json\"\n",
    "    #\"/home/sophie/uncertain-identity-aware-tracking/Bytetrack/YOLOX_outputs/yolox_x_ablation/track_results/MOT17-04-FRCNN/fairmot/fairmot_MOT17_04.json\"\n",
    "    put_val_half_tracking(dbn_file, dataset_name)\n",
    "     \n",
    "\n",
    "\n",
    "    dbn_file= dbn_file.split(\".json\")[0]+\"_DBN_result_half_val.json\"\n",
    "    track_file=base_path+\"_tracking_result.json\"\n",
    "    tracking_result_file=track_file\n",
    "    generate_tracking_result_from_observation(dbn_file, tracking_result_file)\n",
    "    #put_results_on_video (read_data_for_video_generation(tracking_result_file), save_path=gt_video.split(\"gt_video\")[0]+\"fairmot_tracking.mp4\",video_path=gt_video )\n",
    "    length_half = len(read_data_for_video_generation(tracking_result_file).keys())\n",
    "    \n",
    "    \n",
    "    def score_for_various_artificial_observations_mot():\n",
    "\n",
    "        hmm_result_with_visits=pd.DataFrame(columns=[\"nbr of visits\", \"accuracy\", \"recall\", \"f1\"])\n",
    "        re_id_result_with_visits=pd.DataFrame(columns=[\"nbr of visits\", \"accuracy\", \"recall\", \"f1\"])\n",
    "        tracker_result_score= pd.DataFrame(columns=[\"nbr of visits\", \"accuracy\", \"recall\", \"f1\"])\n",
    "        #add error bar here \n",
    "        for j in range(0,2,1):\n",
    "\n",
    "            for i in range (2, 4000 , 200):# range (2, 200 , 10): #[10, 100]:#  [18]: # len(label_track.keys())            \n",
    "                #home_folder=home_folder#''#/home/sophie/uncertain-identity-aware-tracking/Bytetrack/'\n",
    "                observation_file=base_path+\"_DBN_result_with_observations_visits_per_id.json\"\n",
    "                gt_path=os.path.join(\"/data/home/sophie/sophie_2024-10-08/uncertain-identity-aware-tracking/Bytetrack/YOLOX_outputs/yolox_x_mix_mot20_ch/track_results/\",dataset_name+\"/\"+dataset_name+\"_gt.json\")\n",
    "                video_path=gt_video\n",
    "                # '/home/sophie/uncertain-identity-aware-tracking/Bytetrack/YOLOX_outputs/yolox_x_ablation/videos/MOT17-04-FRCNN.mp4'  \n",
    "\n",
    "                #convert_mot_format_to_json_format(gt_path='/home/sophie/uncertain-identity-aware-tracking/Bytetrack/datasets/mot/train/MOT17-04-FRCNN/gt/gt_val_half.txt',\n",
    "                #                          destination_path=gt_path )\n",
    "                adding_atq(nbr_visit=max(50,i), output_file=observation_file, feeder=False, \n",
    "                            track_file=tracking_result_file,#****replace with tracking of fairmot\n",
    "                            dbn_file= dbn_file,\n",
    "                            labels_file=gt_path,\n",
    "                        is_it_random = False, model=False,curated_artificial_visit=None, fairmot=True)\n",
    "                \n",
    "                Hmm_result_file=base_path+\"_with_atq_tracking_with_HMM_result_per_id.json\"\n",
    "                #Hmm_result_file = \"/home/sophie/uncertain-identity-aware-tracking/Bytetrack/YOLOX_outputs/yolox_x_ablation/track_results/MOT17-02-FRCNN_tracking_result.json\"\n",
    "                print(\"start forward backward\")\n",
    "                process_forwad_backward(observation_file,nbr_visit=\"per_id_2_\", pigs_HMM=False, json_save_path=Hmm_result_file, video_path=video_path)\n",
    "                print(\"end forward backward\")\n",
    "                hmm_track = read_data(Hmm_result_file)\n",
    "                print(\"end forward backward2\", hmm_track.keys())\n",
    "\n",
    "                label_track = read_data(gt_path)\n",
    "                acc, rec, f1, idf1= precise_accuracy_track(label_track, hmm_track, gt_base_number=0, basic_tracker=True)\n",
    "                new_row= {'nbr of visits':i, 'accuracy':acc, 'recall':rec, \"f1\":f1, \"idf1\":idf1}\n",
    "                \n",
    "                print(\"****HMM\")\n",
    "                print(new_row)\n",
    "                hmm_result_with_visits = pd.concat([hmm_result_with_visits, pd.DataFrame([new_row])], ignore_index=True)\n",
    "                hmm_result_with_visits.to_csv(base_path+'accuracy_over_nbr_of_visits_with_track_helping.csv')\n",
    "\n",
    "                        \n",
    "                \n",
    "\n",
    "                ####Re_id_part of the work\n",
    "                re_id_track_result_file = base_path+\"_per_id_re_id.json\"\n",
    "                #re_id_tracking_result =produce_re_id_results(track_with_observation_file =observation_file , re_id_track_result_file = re_id_track_result_file )\n",
    "                gt_video_path=\"/data/home/sophie/sophie_2024-10-08/uncertain-identity-aware-tracking/Bytetrack/YOLOX_outputs/yolox_x_mix_mot20_ch/track_results/videos/\"+dataset_name+\"/gt_video.mp4\"\n",
    "                re_id_tracking_result =produce_re_id_results(track_with_observation_file =observation_file , tracking_file=base_path+\"_tracking_result.json\", re_id_track_result_file = re_id_track_result_file , save_video=True, video_path=gt_video_path)\n",
    "\n",
    "                re_id_track = read_data(re_id_track_result_file)\n",
    "                print(\"***Oki before re_id_accuracy\",re_id_tracking_result.keys())\n",
    "                acc, rec, f1,idf1= precise_accuracy_track(label_track, re_id_track,  gt_base_number=-2,basic_tracker=True)\n",
    "                new_row= {'nbr of visits':i, 'accuracy':acc, 'recall':rec, \"f1\":f1, \"idf1\":idf1}\n",
    "                print(new_row)\n",
    "                re_id_result_with_visits = pd.concat([re_id_result_with_visits, pd.DataFrame([new_row])], ignore_index=True)\n",
    "                \n",
    "                re_id_result_with_visits.to_csv(base_path+'accuracy_Re_id_over_nbr_of_visits_with_track_helping.csv')\n",
    "                put_results_on_video ( re_id_tracking_result , save_path= gt_video.split(\"gt_video\")[0]+\"re_id_video.mp4\" , video_path=gt_video)\n",
    "\n",
    "                ########Tracker result\n",
    "                tracking_result = read_data(tracking_result_file)\n",
    "                print(\"***tracker***\",tracking_result.keys())\n",
    "                acc, rec, f1,idf1= precise_accuracy_track(label_track, tracking_result,  gt_base_number=-2,basic_tracker=True)\n",
    "                new_row= {'nbr of visits':i, 'accuracy':acc, 'recall':rec, \"f1\":f1, \"idf1\":idf1}\n",
    "                print(new_row)\n",
    "                tracker_result_score = pd.concat([tracker_result_score, pd.DataFrame([new_row])], ignore_index=True)\n",
    "                \n",
    "                tracker_result_score.to_csv(base_path+'tracking_fairmot.csv')\n",
    "                \n",
    "        print(\"hmm\",hmm_result_with_visits)        \n",
    "        print(\"re_id\",re_id_result_with_visits)\n",
    "        print(\"tracker\",tracker_result_score)        \n",
    "        \n",
    "\n",
    "    score_for_various_artificial_observations_mot()\n",
    "    break\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vizualization code\n",
    "\n",
    "there were an id switch at frame  41  between 556 and None\n",
    "there were an id switch at frame  44  between None and 556\n",
    "there were an id switch at frame  47  between 556 and None\n",
    "there were an id switch at frame  244  between 628 and None\n",
    "there were an id switch at frame  249  between None and 660\n",
    "there were an id switch at frame  256  between 642 and 656\n",
    "there were an id switch at frame  260  between 660 and 655\n",
    "there were an id switch at frame  302  between 660 and None\n",
    "re-id is done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import plotly.graph_objs as go\n",
    "def draw_graph(hmm_based, re_id, dataset_name=\"\"):\n",
    "    artificial_hmm = pd.read_csv(hmm_based)\n",
    "    artificial_re_id= pd.read_csv(re_id)\n",
    "    metric=\"idf1\"\n",
    "    print(artificial_hmm)\n",
    "    all = []\n",
    "    for nbr_visit in np.unique(artificial_hmm[\"nbr of visits\"]):\n",
    "        mean = artificial_hmm[artificial_hmm[\"nbr of visits\"]==nbr_visit].mean()[metric]\n",
    "        std = artificial_hmm[artificial_hmm[\"nbr of visits\"]==nbr_visit].std()[metric]\n",
    "        all.append({\"nbr of visits\":nbr_visit,\"mean f1\":mean, \"std f1\":std})\n",
    "    artificial_hmm_c =pd.DataFrame(all)\n",
    "\n",
    "    all = []\n",
    "    for nbr_visit in np.unique(artificial_re_id[\"nbr of visits\"]):\n",
    "        mean = artificial_re_id[artificial_re_id[\"nbr of visits\"]==nbr_visit].mean()[metric]\n",
    "        std = artificial_re_id[artificial_re_id[\"nbr of visits\"]==nbr_visit].std()[metric]\n",
    "        all.append({\"nbr of visits\":nbr_visit,\"mean f1\":mean, \"std f1\":std})\n",
    "    artificial_re_id_c =pd.DataFrame(all)\n",
    "\n",
    "\n",
    "    fig1 = go.Figure()\n",
    "    fig1.add_trace(go.Scatter(x=artificial_hmm_c[\"nbr of visits\"], y=artificial_hmm_c[\"mean f1\"],\n",
    "                        mode='lines',\n",
    "                        name='HMM based tracker',\n",
    "                        line_color=\"#0000ff\"\n",
    "                        ))\n",
    "    \"\"\"fig.add_trace(go.Scatter(x=artificial_re_id[\"nbr of visits\"], y=artificial_re_id[\"f1\"],\n",
    "                        mode='lines',\n",
    "                        name='Tracker with Re_id',\n",
    "                        #line_color=\"#0000ff\"\n",
    "                        ))\"\"\"\n",
    "    fig1.update_layout(\n",
    "                xaxis_title=\"number of visits\",\n",
    "                yaxis_title='f1 score',)\n",
    "\n",
    "    df = artificial_hmm_c\n",
    "    df2 = artificial_re_id_c\n",
    "    fig = go.Figure([\n",
    "        go.Scatter(\n",
    "            name='Track with HMM',\n",
    "            x=df['nbr of visits'],\n",
    "            y=df['mean f1'],\n",
    "            mode='lines',\n",
    "            #line=dict(color='rgb(31, 119, 180)'),\n",
    "        ),\n",
    "        go.Scatter(\n",
    "            name='Upper Bound',\n",
    "            x=df['nbr of visits'],\n",
    "            y=df['mean f1']+df['std f1'],\n",
    "            mode='lines',\n",
    "            marker=dict(color=\"#444\"),\n",
    "            line=dict(width=0),\n",
    "            showlegend=False\n",
    "        ),\n",
    "        go.Scatter(\n",
    "            name='Lower Bound',\n",
    "            x=df['nbr of visits'],\n",
    "            y=df['mean f1']-df['std f1'],\n",
    "            marker=dict(color=\"#444\"),\n",
    "            line=dict(width=0),\n",
    "            mode='lines',\n",
    "            fillcolor='rgba(68, 68, 68, 0.3)',\n",
    "            fill='tonexty',\n",
    "            showlegend=False\n",
    "        ), \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        go.Scatter(\n",
    "            name='Track with Re-id',\n",
    "            x=df2['nbr of visits'],\n",
    "            y=df2['mean f1'],\n",
    "            mode='lines',\n",
    "            #line=dict(color='rgb(31, 119, 180)'),\n",
    "        ),\n",
    "        go.Scatter(\n",
    "            name='Upper Bound',\n",
    "            x=df2['nbr of visits'],\n",
    "            y=df2['mean f1']+df['std f1'],\n",
    "            mode='lines',\n",
    "            marker=dict(color=\"#444\"),\n",
    "            line=dict(width=0),\n",
    "            showlegend=False\n",
    "        ),\n",
    "        go.Scatter(\n",
    "            name='Lower Bound',\n",
    "            x=df2['nbr of visits'],\n",
    "            y=df2['mean f1']-df['std f1'],\n",
    "            line=dict(width=0),\n",
    "            mode='lines',\n",
    "            fillcolor='rgba(68, 68, 68, 0.3)',\n",
    "            fill='tonexty',\n",
    "            marker=dict(color=\"#444\"),\n",
    "\n",
    "            showlegend=False\n",
    "        ), \n",
    "        \n",
    "        \n",
    "    ])\n",
    "    fig.update_layout(\n",
    "                xaxis_title=\"number of visits\",\n",
    "                yaxis_title=metric+'score',\n",
    "        title=dataset_name+': '+metric+' score over time with 25% of observations being random  (20 repetitions)',\n",
    "        hovermode=\"x\" ) \n",
    "\n",
    "    fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset_name in folders:\n",
    "    dataset_name=  \"MOT20-01\"\n",
    "    base_path= home_folder+\"YOLOX_outputs/yolox_x_ablation/track_results/\"+dataset_name+\"/fairmot/\"+dataset_name.split(\"-\")[0]+\"-\"+dataset_name.split(\"-\")[1]+\"-SDP\"\n",
    "    base_path= home_folder+\"YOLOX_outputs/yolox_x_mix_mot20_ch/Fairmot/\"+dataset_name+\"/\"+dataset_name\n",
    "    hmm_based= base_path+'accuracy_over_nbr_of_visits_with_track_helping.csv'\n",
    "    re_id=base_path+'accuracy_Re_id_over_nbr_of_visits_with_track_helping.csv'\n",
    "    tracker =base_path+'accuracy_Re_id_over_nbr_of_visits_with_track_helping.csv'\n",
    "\n",
    "    draw_graph(hmm_based,re_id, dataset_name=dataset_name)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! rm -r /home/sophie/uncertain-identity-aware-tracking/Bytetrack/YOLOX_outputs/yolox_x_ablation/videos/MOT17-04-FRCNN_with_atqper_id_2_.mp4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "evaluation2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
